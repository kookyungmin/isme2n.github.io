---
layout: post
title:  "[Tensorflow]5.Multi-variable linear regression(2)"
date:   2017-08-04 19:59:00 -0500
comments: true
categories: tensorflow
---

## Multi-variable linear regression(2)
<br>
[4.Multi-variable linear Regression(1)](https://kookyungmin.github.io/tensorflow/2017/08/04/tensorflow05.html)에 이어서 포스팅을 하겠습니다.
<br>
이번 장에서는 tensorflow로 처음부터 끝까지 간단하게 데이터를 훈련시키고 예측까지 시켜보겠습니다.
<br>
<br>
전 장에서 언급한 예제인 어떤 학생의 국어 영어 수학 과학 점수를 입력하면 대학 합격 유무를 알려주게끔 학습을 시켜 보겠습니다.
<br>
<br>
먼저, 맨 처음 tensorflow를 import~~!
<br>
<br>

>```python
>import tensorflow as tf
>```

<br>
<br>
그리고 실제 대학생의 데이터를 선언해줍니다.
<br>
<br>

>```python
>x_data=[[100,92,95,72],[92,88,80,66],[70,59,68,77]]
>// [학생1[국,영,수,과],학생2[국,영,수,과],학생3[국,영,수,과]]
>y_data=[[1],[1],[0]] //합격(1) 합격 불합격(0)
>```

<br>
<br>
그 다음 학습에 필요한 변수들 선언!
<br>
<br>

>```python
>//한 명당 속성이 4이므로 x_data를 담을 틀인 X의 shape는 [None,4]
>X=tf.placeholder(tf.float32,shape=[None,4]) 
>Y=tf.placeholder(tf.float32,shape=[None,1])
>//W의 shape는 X의 shape와 행렬곱해서 Y의 shape가 되어야하므로 [4,1]
>W=tf.Variable(tf.random_normal([4,1]),name='weight')
>b=tf.Variable(tf.random_normal([1]),name='bias')
>```

<br>
<br>
hypothesis 정의
<br>
<br>

>```python
>//행렬 곱으로 다시 정의된 hypothesis
>hypothesis=tf.matmul(X,W)+b
>```

<br>
<br>
cost 함수 정의
<br>
<br>

>```python
>//예측 값과 실제 값의 차이
>cost=tf.reduce_mean(tf.square(hypothesis-Y))
>```

<br>
<br>
cost 최소화
<br>
<br>

>```python
>//실제 값과 예측 값의 차이를 계속 줄여준다.
>optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.00001)
>train=optimizer.minimize(cost)
>```

<br>
<br>
노드들을(tensor) 그래프화 
<br>
<br>

>```python
>sess=tf.Session()
>//변수 초기화
>sess.run(tf.global_variables_initializer())
>```

<br>
<br>
학습을 시작합니다~
<br>
<br>

>```python
>//반복문을 돌면서 계속 데이터를 넣는다->w,b가 cost가 최소가 되게 계속 이동
>for step in range(2001):
>	cost_val,_=sess.run([cost,train],feed_dict={X:x_data,Y:y_data})})
>	if(step%100==0):
>		print(step,cost_val)
>```

<br>
<br>
학습 끝! 이번에도 step마다 cost가 줄어드는 것을 보실 수 있습니다.
<br>
<br>

>![image](/image/tensorflow_img/m2.png)

<br>
<br>
과연 학습이 잘 되었나 확인해볼까요? 국어 88점, 영어 92점, 수학 90점, 과학 80점 과연 결과는???
<br>
<br>

>![image](/image/tensorflow_img/m3.png)

<br>
앗?? 이럴수가 0과 1사이가 아닌 수가 나와버렸네요~ 1과 더 가깝다고 합격이라고 예측하기에도 힘들죠
<br>
<br>
이것을 해결해 줄 것은 바로 다음에 배울 분류(classification)입니다!!!!
<br>
<br>
classification(분류)에 대해 간단히 배운 후 다시 실행해 보겠습니다~!
<br>
일단은 다수의 속성을 가진 데이터에 대해 학습을 할 때는 행렬 곱을 이용한다는 것
<br>
변수 선언 시 shape가 중요하다는 것만 기억하셔도 좋습니다~
<br>
<br>
전체 코드
<br>
<br>

>![image](/image/tensorflow_img/m1.png)


<br>
<br>
<br>
- - -
이전 장 [[Tensorflow]4.Multi-variable linear regression(1)](https://kookyungmin.github.io/tensorflow/2017/08/04/tensorflow05.html)
<br>
다음 장 [[Tensorflow]6.Logistic(regression) classifier(1)](https://kookyungmin.github.io/tensorflow/2017/08/04/tensorflow07.html)
<br>
<br>
<br>
By 꾸리
