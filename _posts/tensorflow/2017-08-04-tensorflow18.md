---
layout: post
title:  "[Tensorflow]17.MNIST 99.4%(END)"
date:   2017-08-08 21:00:00 -0500
comments: true
categories: tensorflow
---

## 14.MNIST 99.4%
<br>
<br>
이번 장에서는 MNIST예제를 Convolution Neural Network를 적용하여 작성해보겠습니다.
<br>
<br>
저번에는 98%의 정확도가 나왔는데 CNN을 적용하면 과연 더 올라갈까요???
<br>
시작해보겠습니다.
<br>
<br>
먼저, 맨 처음 tensorflow를 import~~!
<br>
<br>

>```python
>import tensorflow as tf
>```

<br>
<br>
그리고 학습 데이터를 가져오기 위해 다음을 입력해줍니다
<br>
<br>

>```python
>from tensorflow.examples.tutorials.mnist import input_data
>mnist=input_data.read_data_sets("MNIST_data/",one_hot=True)
>```

<br>
<br>

![image](/image/tensorflow_img/mn3.png)

<br>
<br>
그러면은 위와 같이 tensorflow가 데이터를 알아서 가져와줍니다.
<br>
<br>
그 다음 학습에 필요한 변수들 선언!
<br>
<br>

>```python
>X=tf.placeholder(tf.float32,[None,784])
>X_img=tf.reshape(X,[-1,28,28,1]) //3차원벡터로 바꾸어줍니다.
>Y=tf.placeholder(tf.float32,[None,10])
>keep_prob=tf.placeholder(tf.float32)//drop out에 사용되는 것입니다.
>```

<br>
<br>
Convolution+pooling Layer 구축
<br>
<br>

>```python
>//convolution+pooling layer 1
>W1=tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01))
>L1=tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')
>L1=tf.nn.relu(L1)
>L1=tf.nn.max_pool(L1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')
>L1=tf.nn.dropout(L1,keep_prob=keep_prob)
>
>//convolution+pooling layer 2
>W2=tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))
>L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')
>L2=tf.nn.relu(L2)
>L2=tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')
>L2=tf.nn.dropout(L2,keep_prob=keep_prob)
>
>//convolution+pooling layer 3
>W3=tf.Variable(tf.random_normal([3,3,64,128],stddev=0.01))
>L3=tf.nn.conv2d(L2,W3,strides=[1,1,1,1],padding='SAME')
>L3=tf.nn.relu(L3)
>L3=tf.nn.max_pool(L3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')
>L3=tf.nn.dropout(L3,keep_prob=keep_prob)
>
>```

<br>
<br>
Fully connected Layer(분류기 단계)를 위해 reshape
<br>
<br>

```python
L3=tf.reshape(L3,[-1,4*4*128])
```

<br>
<br>

Fully connected Layer(분류기 단계) 구축

<br>
<br>

>```python
>//Fully connected layer 1
>W4=tf.get_variable("W4",shape=[4*4*128,625],initializer=tf.contrib.layers.xavier_initializer())
>b4=tf.Variable(tf.random_normal([625]))
>L4=tf.nn.relu(tf.matmul(L3,W4)+b4)
>L4=tf.nn.dropout(L4,keep_prob=keep_prob)
>
>//output layer 
>W5=tf.get_variable("W5",shape=[625,10],initializer=tf.contrib.layers.xavier_initializer())
>b5=tf.Variable(tf.random_normal([10]))
>
>```

<br>
<br>
hypothesis 정의
<br>
<br>

>```python
>hypo=tf.matmul(L4,W5)+b5
>```

<br>
<br>
cost 함수 정의
<br>
<br>

>```python
>cost_i=tf.nn.softmax_cross_entropy_with_logits(logits=hypo,labels=Y)
>cost=tf.reduce_mean(cost_i)
>```

<br>
<br>
cost 최소화
<br>
<br>

>```python
>//AdamOptimizer를 이용하면 최솟값을 더 잘 찾을 수 있습니다~
>optimizer=tf.train.AdamOptimizer(learning_rate=0.001)
>train=optimizer.minimize(cost)
>```

<br>
<br>
노드들을(tensor) 그래프 화 
<br>
<br>

>```python
>sess=tf.Session()
>//변수 초기화
>sess.run(tf.global_variables_initializer())
>```

<br>
<br>

데이터가 많기에 역시 batch 시스템을 이용합니다~~!

<br>
저번 예제와 학습하는데 사용하는 코드는 똑같습니다.
<br>
<br>

>```python
>training_epochs=15 //15번 거쳐서 학습을 시킨다
>batch_size=100 //100개 씩 데이터를 가져온다
>for epoch in range(training_epochs): 
>    avg_cost=0 //학습 1번 당 평균 cost값
>    //데이터의 총 갯수를 100으로 나누어준다. -> 몇 번에 거쳐 데이터를 가져올 지 계산
>    total_batch=int(mnist.train.num_examples/batch_size) 
>    for i in range(total_batch): //100개 씩 데이터를 가져와 학습시킨다.
>        batch_xs,batch_ys=mnist.train.next_batch(batch_size) 
>        c,_=sess.run([cost,train],feed_dict={X:batch_xs,Y:batch_ys,keep_prob=0.7})
>        avg_cost+=c/total_batch
>    print('Epoch:','%04d'%(epoch+1),'avg_cost','{:.9f}'.format(avg_cost))
>```

<br>
<br>
학습 끝! 학습할 때마다 점점 cost 값이 줄어드시는 것을 볼 수 있습니다.
<br>
학습하는데 층이 많다보니 시간이 정말 많이 걸립니다ㅠㅠ 45분이나 ㅠㅠ
<br>
이렇듯 데이터가 많고 층이 많을수록 정확해지는 대신에 시간이 오래걸려요
<br>
좋은 컴퓨터가 필요합니다 ㅋㅋㅋㅋㅋㅋㅋ
<br>
<br>

>![image](/image/tensorflow_img/cnn2.png)

<br>
<br>
과연 학습이 잘 되었나 확인해볼까요? 
<br>
tensorflow에서 기본적으로 제공하는 test데이터를 이용해서 정확도를 측정해보겠습니다.
<br>
<br>

>![image](/image/tensorflow_img/cnn3.png)

<br>
놀랍게도 정확도는 99.4%까지 나옵니다~~ 정말 대단합니다! 
<br>
<br>
<br>
<br>
이렇게 여러분과 함께 tensorflow를 이용해서 머신러닝, Neural Network, CNN까지 배워봤는데요!
<br>
<br>

미래를 예측하고 싶은 우리 사회에 정말 없어서든 안 될 기술이라고 생각합니다!!

<br>
tensorflow 배우시는 걸 적극 추천합니다! ㅋㅋㅋㅋ
<br>
<br>
일단 tensorflow에 대한 포스팅은 여기까지하구요~~!
<br>
<br>

나중에 시간나면 RNN,tensorflow 용어 등 추가적으로 포스팅 할게요!!
<br>
<br>
<br>
<br>
<br>
<br>
지금까지 제 글을 봐주신 여러분께 감사드립니다~~~
<br>
<br>

전체 코드
<br>
<br>

>![image](/image/tensorflow_img/cnn1.png)

<br>
<br>
<br>
- - -
이전 장 [[Tensorflow]16.Convolutional Neural Network(2)](https://kookyungmin.github.io/tensorflow/2017/08/08/tensorflow17.html)

<br>
<br>
<br>
By 꾸리
