---

layout: post

title:  "[Tensorflow]2.Linear Regression(1)"

subtitle: "[Tensorflow]2.Linear Regression(1)"

date:   2017-08-04 08:59:00 -0500

categories: Study

tags: tensorflow

---

## Lenear Rigression(1)

<br>
이번 시간에는 tensorflow를 이용하여 머신러닝(기계학습)을 구현하는 방법을 간단하게 설명하고 간단한 예제 실행도 해보겠습니다.
<br>
[0.tensorflow는 무엇인가?](http://kookyungmin.github.io/tensorflow/2017/08/03/tensorflow01.html) 에서 간단하게 설명했었지만
<br>
머신러닝은 기존 훈련 데이터들을 이용하여 데이터를 구분지을 수 있는 판별식(WX+b)를 구한 후
<br>
새로운 데이터가 왔을 때 이를 예측하는 방법이라고 하였습니다.
<br>
말로 설명하면 아직 감이 안 오시는 분들이 많죠~ 직접 예제를 실행해보면서 알아가는 시간을 갖겠습니다.
<br>
<br>
<br>
머신러닝은 크게 4단계로 이뤄진다고 보면 됩니다.
<br>
1.training data를 준비한다.
<br>
2.Hypothesis(판별식)을 설정한다.
<br>
3.Cost함수를 설정한다.
<br>
4.cost함수를 최소화시키는 W,b를 구한다.
<br>
<br>
<br>

## 1.Training data set을 준비한다.
<br>

>여기서 Training set이라고 하면 x_data(속성 값), y_data(실제 값)을 말합니다.
><br>
><br>
>예를 들어 어떤 사람의 수학 점수를 가지고 대학교 합격,불합격 여부를 알고 싶다고 합시다.
><br>
>그러면 학습을 하기 위해서 실제 데이터들이 필요한데, 학습데이터는 다음과 같은 형태입니다.
><br>
>
>```python
>x_data=[100,58,95,72,83]//학생1 100점,학생2 58점,학생3 95점, 학생4 72점,학생5 83점
>y_data=[1,0,1,0,1]  //합격(1) 불합격(0) 합격 불합격 합격
>```

<br>

## 2.Hypothesis(판별식)을 설정한다.
<br>

>여기서 Hypothesis는 데이터들을 구분할 수 있는 직선 정도라고 생각하면 됩니다.
><br>
>그리고 이는 어떤 데이터가 주어졌을 때 예측한 값이 됩니다
><br>
>
>```python
>hypothesis=X*W+b
>```
>
<br>

## 3.Cost함수를 설정한다.

<br>

>cost 함수는 우리가 hypothesis로 설정한 직선으로 구한 예측 값과 실제 값이 얼마나 다른가를 나타내는 함수정도로 생각하면 됩니다.
><br>
>cost함수를 일단 다음과 같이 정의하겠습니다.
><br>
>
>![image](/image/tensorflow_img/cost.png)
>
><br>
>
>H(x^i):예측 값 
><br>
>y^i:실제 값  
>
><br>
>
>```python
>cost=tf.reduce_mean(tf.square(hypothesis-Y))
>```
>
><br>
>tf.reduce_mean는 평균을 구해주고, 
>tf.square는 제곱을 해준다.

<br>

## 4.cost함수를 최소화시키는 W,b를 구한다.

<br>

>컴퓨터는 데이터를 훈련시키면서 cost 함수(우리가 예측한 값과 실제 값의 차이)를 작게 하는 W와 b 값을 구합니다.
><br>
>W,b를 구하는 법은 Gradient decent algorithm(경사감소법)을 이용하는데 구체적인 방법은 알지 못해도 좋아요.
><br>
>왜냐하면 컴퓨터가 알아서 하기 때문이죠!!!!
><br>
><br>
>심지어 W,b도 컴퓨터가 스스로 변경한답니다!!
><br>
><br>
>
>```python
>optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0001)
>train=optimizer.minimize(cost)
>```
><br>
>tf.train.GradientDescentOptimizer는 경사감소법을 해주는 기계로 생각
><br>
>learning_rate은 cost함수를 최소화 시킬 때 W,b값을 변화시키는 정도로 생각 (너무 커서도 작아서도 안 된다!)
><br>
>optimizer.minimize(cost) cost를 최소화시킴

<br>
<br>
다음 장에서 직접 tensorflow를 이용해서 직접 훈련도 시켜보고 예측 값도 구해보겠습니다.
<br>
<br>
<br>
- - -
이전 장 [[Tensorflow]1.Tensorflow의 자료형](https://kookyungmin.github.io/tensorflow/2017/08/03/tensorflow02.html)
<br>
다음 장 [[Tensorflow]3.Linear Regression(2)](https://kookyungmin.github.io/tensorflow/2017/08/04/tensorflow04.html)
<br>
<br>
<br>
By 꾸리
